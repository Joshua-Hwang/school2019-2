Prereq maths------------------------------------------------------------
For discrete logarithms to exist and be unique (with respect to equivalence
classes)

log_a c mod n

n needs to be prime
a needs to be a generator

I hope you remember the extended euler's algorithm

Information security------------------------------------------------------
There are three things we can do with risk,
Accept it,
Transfer it (insurance),
Reduce it

Residual risk is the amount of risk that remains after security measures
have been applied.

Information security is all about protective measures.

Some types of protective measures:
Preventative measures (prevent damage),
Detective measures (know when, how and who caused damage),
Reactive measures (allow recovery to assets)

information security is about dealing with potential damages.

Information security can be categorised into the CIA triad:
Confidentiality, Privacy and Secrecy (prevent unauthorised disclosure of information),
Integrity (Prevent unauthorised modification of information),
Availability (prevent unauthorised witholding of information i.e. DoS),

The above three aspects along with the bottom two make up the main
concepts of information security.
Authenticity (make sure the author/sender is as claimed),
Non-repudiation (people can't escape contracts by claiming that it was a forgery)

Risk management------------------------------------------------------------
The process concerned with identification, measurements, control and
minimisation of security risks in information systems to a level appropriate
to what the asset is worth.

Risk management helps determine and optimise for the appropriate cost/benefit
for protective measures.

Identify, measure, control and minimise or eliminate attacks.
This is done through: risk assessment, cost benefit analysis, selection,
implementation and evaluation of security features and countermeasures and
an overall security review.

[Examples of these are in the notes.tex or notes.pdf]
The definition of risk as determined by ISO/IEC 27000:2018 is,
"effect of uncertainty of objectives". Where an objective is a result to
be achieved.

The definition of threat as determined by ISO/IEC 27000:2018 is,
"potential cause of an unwanted incident, which can result in harm to a system
or organization"

The definition of vulnerability as determined by ISO/IEC 27000:2018 is,
"weakness of an asset or control that can be exploited by one or more
threats"

The definition of risk assessment as determined by ISO/IEC 27000:2018 is,
"overall process of risk identification, risk analysis and risk evaluation."

Risk analysis----------------------------------------------------------------
A qunatitative risk analysis largely resolves around the following.
A model for quantifying the cost is taking the expected value of the
event occuring (prob * impact).

ARO (Annualised Rate of Occurrence)
Number of times a year.

SLE (Single Loss Expectancy)
The impact of a single type of this event occurring.

ALE (Annualised Loss Expectancy)
ALE = ARO * SLE

It is often difficult however to get these probabilities and also to
quantify the impact and cost of an event.

Instead we might use a more qualitative method.
Risk assessment matrices.

ISO31000:2018 Risk Management Principles and Guidelines
The flow chart is referenced in images/standards-flow.png

Trust------------------------------------------------------------------------
When an entity is trusted is different than if they are trustworthy.
Hopefully the difference is obvious.

Direct trust can be developed by two parties.

Indirect trust involves trusting a third party who claims others are trustworthy.

Access Control----------------------------------------------------------------
There are two separate but important functions to establish identity:
Establishing the identity which involves:
    Identification - Determine who the entity is
    Authentication - Verity and prove you are who you say you are.
Authorisation, once identity is established a decision can be made about
granting or denying access.

Most access control is determined by identity. Which has a second benefit of
accountability (we can track who did what when in the system).

How do you prove (authenticate) your identity?--------------------------------
Passwords have been the goto for years. It is based on "something you know"

The problems include:
forgetting passwords
same password in multiple places
weak passwords
passwords not kept secret
default passwords

Passwords can be
guessed via bruteforce
social engineering and phising attacks
eavesdropping
bogus (fake) interfaces which look like login screens
keylogging

Storing passwords also leads to a point of vulnerability.

Cryptography------------------------------------------------------------------
Cryptography is about keeping messages secure.
Literally means secret writing.

Cyrptanalysis is the science of breaking message security.

Cryptology is the theory associated with cryptography and cryptanalysis.

The aim of cryptography is confidentiality but it can also be used to
authenticate a user, ensure no messages have been modified and
might even be used for digital signing.

Hash functions----------------------------------------------------------------
hash functions compress an arbitrarily long input x into a fixed size output.
hash functions should be designed to be easy to compute.

one-way hash functions have the one-way property. It is computationally
infeasable to find x given h(x). One-way is also called pre-image resistance.

Now cryptographic one-way functions have another property called
collision resistance.
Strong collision resistance means its hard to find two distinct x1 and x2 such that h(x1) = h(x2)
Weak collision resistance (aka 2nd pre-image resistance) given a specific
y=h(x1) it is hard to find x2 such that h(x1) = h(x2)

An ideal one-way cryptographic function can be visualised as such.
"Has this input arrived before?" If yes rereturn the output. If no then
make a random sequence. This model is called a *random oracle model*

To find a weak collision we need 2^n but for a strong collision we just need
2^{n/2} since birthday paradox.

A cryptographic hash is considered broken if collisions can be found with
significantly less work than brute force.

An offline attack on passwords is when the attacker has access to the hashes
of the password. The hacker can then apply numerous exploits on the file
to get a collision/reverse the hash.

Cryptography keys------------------------------------------------------------
The problem with using a different and hidden protocol for all communications
between people is that no one can talk to new people. Instead we have
cryptography keys which alter the algorithm in a way that still ensures it's
impractical to crack. This is Kerckhoff's Principle,
    "The security of a cipher should rely on the secrecy of the key only."

Types of attacks------------------------------------------------------------
Much like in MATH3302 we have the different types of cipher attacks:
Ciphertext only
    The attacker has obtained a piece of ciphertext but no decoding
Known-plaintext attack
    The attacker has obtained a piece of ciphertext and its corresponding
    plaintext
Chosen-plaintext attack
    The attacker has temporary access to the encryption machine
Adaptive Chosen-Plaintext attack
    The attacker has the encryption machine for quite some time

Different ciphers-------------------------------------------------------
The lecture talks about a few ciphers
The Caesar cipher [remember MATH3302]
Monoalphabetic substitution cipher (a set permutation of the alphabet)
Vigenere cipher [remember MATH3302]
One time pads

Transposition cipher (we create a matrix of the message (secret rows and
columns) we then read off the matrix in the transpose way
[see transpositioncipher.png].

Computational security is security from the key length, the resources of the
attacker and how long the information needs to be kept secret.

Perfect security is explored as well.
A proof involving the one time pad is shown.

Creating a cipher---------------------------------------------------------------
As we learnt in MATH3302 there is no way yet to practically measure the security
of a cipher. It's either "too hard" to wrap our heads around or it's founded on
a computational problem that does not have efficient algorithms for.

The goal of creating a cipher is computation security, this is where the best
attack option is brute-force there are no shortcuts to get to the key.
From here it's simply key length that determines security; it's a simple brute
force job.

The only way we can "prove" this is to show that our cipher is secure against
all CURRENTLY known attacks.

Symmetric ciphers------------------------------------------------------------
Many modern ciphers are product ciphers.
A product cipher is a composition of either substitutions or permutations
(which are also just substitutions). They are iterated several times to increase
security.

Feistel ciphers are what you've already seen in MATH3302 so I hope you remember
them. Many product ciphers are Feistel ciphers.

Transposition involving swapping the two blocks being encrypted.
Substitution using S-boxes.
Decryption is also encryption but with the round keys in reverse order.

Note that the F function does not have to be reversible since XOR twice results
in the original solution.

DES---------------------------------------------------------------------------
DES uses 16 rounds with 64 bit blocks and 56-bit key with 8 bits for parity.
The round function expands 32 bits into 48 bits.
The S-box converts 6 bits into 4 bits

The DES challenge was an attempt to break the DES by bruteforce.
1997 took 3 months
1998 took 3 days and cost $250K
1999 took 22 hours with machine created from the 1997 and 1998 challenges
2006 took 7 days for $10K (COPACOBANA)

Each new key bit doubles the time required for a brute force. This means a
128-bit key will take 90 billion billion years for COPACOBANA to crack it.

Choosing to double DES via
c = E_{K2}(E_{K1}(p)) and
p = D_{K1}(D_{K2}(c))

Now we should theoretically have double the key size. Unfortunately 2-DES is
vulnerable to meet-in-the-middle attacks.

If you manage to find the inbetween value (so E_{K1}(p) = D_{K2}(c)) then we
can look for a collision between the two key spaces.
Because we need x this is technically a known-plaintext attack.

Instead we use triple DES.
c = E(D(E(p)))

You may not that we're decrypting for the second function this is so that if
K1=K2=K3 then this is essentially single DES. Which helps with compatibility.

AES--------------------------------------------------------------------------
In 1998 NIST (US National Institue of Standards and Technology) announced
development of AES
2000 NIST chose the cipher we know as AES.

Selection process for AES was public and 15 candidates were brought.
5 were found to be broken
5 weren't that good
5 finalists
* Serpent
* Rijndael
* Twofish
* Mars (IBM)
* RC6 (RSA Data Security Inc.)

Rijndael won with its symmetric block cipher (not Feistel).
128-bit data blocks
You could choose key lengths with 128 (10 rounds), 192 (12 rounds)
and 256 bytes (14 rounds). It could even be
extended though this feature is not part of the standard.

AES is seen as a block of data (an actual square).
Initial round
Adds the round key via XOR

Normal rounds
Each byte is substituted via a lookup table.
Each row is then shifted cyclically.
The columns are mixed
Add the round key like the initial round

Final round
Same as Normal rounds but without mixing rows.

The choice of S-box was based on a bunch of stuff that won't be covered.

The US Government
AES-128 is used for SECRET classification
AES-192 or AES-256 for TOP SECRET

AES and block cipher modes-----------------------------------------------------
ECB (electronic book mode)
This involves generating a single key and XORing this key to each block of
input. This is obviously weak since we're using the same key for mutliple
plaintext and there is not dependency between the blocks.

The ECB mode is simple, implementation, parallelisable,
errors only affect that single block (blocks aren't dependent) but it is weak.
Replay attacks are possible. If the block sizes are small enough we could
potentially build a table of dictionary attacks for a block cipher.

CBC, CFB and OFB build off of ECB by embedding dependency and feedback.

CBC (cipher block chaining mode)  uses a single key but now the encrypted block is XORed with the next message
block before being XORed with the key. The first block is XORed with an
initialisation vector (IV). Decryption involves XORing the key then XORing the
IV (in that order). CBC cannot be parallelised since dependency.

Turns out IV does not need to be secret but it should be changed frequently.

CBC can actually self-recover from bit errors. [ZZZ I have no idea how or why]
This property could be used to determine the
differences caused by changes in bits.
CBC is the most commonly used cipher mode but may soon be overtaken by Counter
Mode.

CFB (cipher feedback mode) is very similar to CBC. We start with an initial
vector and encrypt it. We take this encrypted vector and XOR the message onto
it; this is our first cipher block. We take this cipher block and use this as
our new initial vector which we encrypt and XOR the message onto.

We can extend the CFB by introducing an arbitrary k bit shift after getting the
new intial vector. We introduce this k shift so we can get rid of error bits.
By shifting k bits in an n sized block we can get rid of the error after n/k + 1
repeats (n/k block and the initial block that started it).

CFB can actually recover from a whole block of the cipher getting deleted.
[ZZZ no idea how again]

OFB (output feedback mode) provides a slight modification of CFB. In OFB we take
our intial vector and encrypt it. We then take this encrypted block and use it
as the next initial vector. After this we take the same encrypted vector and XOR
it to the message. Note in this model each following message is not
dependent on the previous one. Only the number of times the initial key was
encrypted.

Obviously if an error occurs in the setup then it won't propogate to the other
messages because the messages are independent of previous message blocks.

This method also allows us to optimise via precomputing the key and encryptions.
This method cannot recover from the loss of an entire ciphertext block however.

CTR (counter mode) we use a completely different approach. We generate a nonce
and a counter. After every round we will bump up the counter and either XOR,
concatenate or add it to the nonce (if the nonce isn't random then we must only
use concatenation). We pass these nonce+counters into our encryptor and then
XOR or message onto the encrypted part.

Much like in the OFB the ciphers aren't dependent on each other but simply
dependent on the counter size. This means that errors aren't propogated.

[00:00 week 6 see video for something]

Side Channel Attacks------------------------------------------------------------
are attacks against the implementation rather than the
algorithm itself.
We gain new information like, timing, power consumption etc.

AES implementations have been broken using Side Channel Attacks
One implementation uses caches which makes certain inputs faster than usual.
You could probably use this information to attack the system.

Interestingly Intel and AMD have inbuilt AES instructions.

Stream ciphers vs Block ciphers-----------------------------------------------
As you should already know block ciphers take blocks of the input and converts
it into blocks of encrypted input.
A stream cipher generates a stream of pseudorandom keys (unlike OTP which uses
truly random key stream)

Encryption usually involves XORing the pseudorandom keys.

RC4 (aka Ron's Code who is also the R in RSA) is the most widely used
stream cipher, implemented in MS Word, Excel, Wireless LANs (WEP).

RC4 has been found to have some vulnerabilities.

Lamport's Hashed Password Scheme
The idea is the create a sequence of one-time passwords using a one-way hash
function.

The client selects an initial secret password p_0
We can compute the p_n = h(p_{n-1}).
The server is keeping a track of the current p and current n.
The server sends the client the current counter.
User sends p_n and the server checks its own version with what was sent.
Now the server DECREMENTS n by one. This way that if eavesdropping occurs
that the entire sequence doesn't get destroyed.

Password cracking--------------------------------------------------------------
Dictionary attacks
Brute-force attacks
Hybrid which is common words + some random numbers

These are off-line attacks where the attacker has access to the hashed passwords
(and plenty of time with them). This is kinda like a ciphertext only attack.
An on-line password attack involves the attacker talking to a live system. This
is obviously much harder since the system might give you timeouts.

What if two users happen to choose the same password? Consider the /etc/passwd
which contain the hashed passwords of all users. If a user shares the same
password with another user then they will know the other user's password.

This is solved via SALTing. Unix uses 12 random bits in a modified DES algorithm
to fix this.

You may think that PINs with 4 digits are weak but in reality attackers must
always plug the PIN into a live system. After 3 unsuccessful attempts the
ATM 'eats' the card!

Authentication-----------------------------------------------------------------
How on earth do you send your password over the internet to verify?
You COULD send the hashed password over the network but an eavesdropper can
perform a replay attack.

Instead we choose a Challenge-Response Protocol.
The server gives a client a "challenge", c
(often called the nonce number-used-once)

Client calculates a response which is a cryptographic hash of c AND the password
either as r = h(c||p) (concatenation) or r = h(c XOR p).

Note that *choosing* the challenge does not affect the strength. The only
requirement is that the challenge only happens once.

HTTP--------------------------------------------------------------------------
HTTP has two modes, Basic and Digest.

In basic:
1. Browser sends a GET request to a web server.
2. Server says that the user is not authorised and requires basic authentication
3. User sends another GET request with authentication detail

The issue here is that the password is in cleartext

In digest:
1. Browser sends a GET request to a web server.
2. Server says that the user is not authorised and requires digest
authentication. A nonce is provided as a digit.
3. The browser then computes a hash with
(username, password, realm (folder you want to access), nonce, URL)

The problem with this new system is that the main password must be stored
in the server. It is also still vulnerable to man in the middle attacks.

SSH--------------------------------------------------------------------------
SSH-1 can be authenticated via multiple methods; password, public key etc.
The password authentication is still vulnerable to man in the middle attacks.

The public key authentication is actually better since it isn't vulnerable
to man in the middle attacks.

SSH-2 uses stronger key exchanges including:
Diffie-Hellman
RSA
Generic Security Service Application Program Interface (GSS-API)
AES Galois Counter Mode
Elliptic Curve Algorithm
SHA-2 Data Integrity Verification

Asymmetric encryption-------------------------------------------------------
From the example solutions below we need more bits and more computing power to
ensure an asymmetric system is secure compared to a symmetric one. A solution
might be to intiate a conversation with an asymmetric system then exchance
symmetric keys to continue in a more efficient symmetric system.

Diffie-Hellman---------------------------------------------
In the Diffie-Hellman key agreement protocol we make use of the fact that
discrete logarithms are hard.
Alice and Bob wish to communicate.
1. Alice and Bob initially agree on large prime p and large generator g.
2. Both Alice and Bob choose random x and y and send g^x mod p and g^y mod p
to the other party respectively.
3. Alice and Bob generate the key both by taking g^{xy}. Doing this requires
knowing g^x and y and g^y and x which both Alice and Bob have but no
eavesdropper could.

Of course this all breaks down if the eavesdropper can actually intercept and
communicate as well. This is a Man in the middle (MITM) attack. We need some way
authenticate Alice and Bob.

This is not a trapdoor one-way function however since this is a public key
sharing protocol and not a workable cipher.

RSA------------------------------------------------------------------
Name after the last names of Ron Rivest, Adi Shamir and Leonard Adleman.
We take two primes p and q.
n = p*q
choose two values e and d such that
e*d = 1 mod (p-1)(q-1)
Now encrypt the message m into cipher c as such
c = m^e mod n
m = c^d mod n

Here d is the secret key that allows decryption.

According to RSA Security (2003) 1024 bit RSA key is equivalent to 80 bit key of
a symmetric cipher. This is because you need to factor 1024 bits rather than
brute force it like in symmetric keys.

2048 bit RSA ~ 112 bit symmetric key
3072 bit RSA ~ 128 bit symmetric key

Elliptic Curve Cryptography-------------------------------------------
Encryption systems like El Gamal are based on discrete logarithm problems.
Elliptic curce space is preferred since best known algorithms known for
computing discrete logarithms or factoring become much slower in ECC.

Multi-factor authentication------------------------------------------------
Two-factor authentication involves using one of the two methods:
Something you know and something you are (password and fingerprint)
Something you know and something you have (password and physical key)
Something you are and something you have (fingerprint and physical key)

For example using an ATM requires a card and knowing the PIN.

SecureID is a way to have a "physical key" for internet usage. This makes use of
a piece of hardware that generates "random" numbers which are synced with an
authentication server.

Biometrics------------------------------------------------------------------
Criteria for good biometrics involve:
Universality (everyone must have one)
Distinctiveness (should be unique for each person)
Permanence (must not change)
Performance (must be fast to recognise)
Acceptability (are people okay using this body part for identification)
Circumvention (how easy to trick the system and perform replay attacks)

Tiny fingerprint features called Minutiae are stored instead of an image.

Verification mode is a one-to-one match with a single template in the database.
Identification mode is a one-to-many match.

Intuitively the identification mode is more likely to pop up a false accept.

There are two main types of errors:
False accept (False Match) which allows non-users access thinking they are the
template.
False reject (False Non-Match) which prevents true users from accessing their
own template.
In addition:
Failure to Enrol (FTE) failure to create a valid template from a new user's
input.

I'm trusting that you can actually calculate the false match and false non-match
[take a look at slide 30 of week 5 biometrics]

Authentication-----------------------------------------------------------------
All this fancy asymmetric key cryptography doesn't hold up to MITM attacks.
RSA offers a solution. Since encryption and decryption are the same thing in RSA
we can actually "decrypt" first then "encrypt". The only person that can decrypt
is the one who possesses the secret key thus it makes a good digital signature.

To prove you identity you decrypt whatever they send your way and then echo it
back to them.

RSA can also be used to verify a file. All we have to do is send the file but
"decrypted". The problem is that RSA is slow and a simple file would be a pain
to encrypt and decrypt. Instead we take the file and hash it so we have a small
fingerprint of the file. We then "decrypt" the hash and send the original file.
This way the customer can take the hash of the received file themselves and
verify accordingly.

There still remains a problem. The initial step of mapping an identity to a key.
We can solve this using a trusted third party that will vouch for an
identity-key binding. The document created from the third party vouching for
identity is called a digital signature.

Much like in MATH3302 we create a pyramid of trust. At the top we have a trusted
authority (Root CA Certificate) then we have bunch of untrusted authorities
below it (and some having certificates from other untrusted authorities which
eventually lead to a certificate for the root authority. This is called to
certificate chain. Trust is bootstrapped via other means (use your imagination).

An example of a certificate is the X.509. The version 3 certificate is
Certificate
- version
- serial number
- algorithm id
- issuer
- validity (valid thru)
- subject
- subject's public key info
  - public key algorithm
  - subject's public key
- issuer unique identifier (optional)
- subject unique identifier (optional)
- extensions (optional)
...
- certificate signature algorithm
- certificate signature

When the private key is compromised/leaked we need to do a few things.
Stop using the key entirely, revoke the certificate, ensure programs and
browsers are constantly checking validity of certificates.
The CA adds the certificate to a Certificate Revocation List (CRL) which the CRL
publishes.

"A Public Key Infrastructure (PKI) is a set of hardware, software, people,
policies and procedures needed to create, manage, distribute, use, store and
revoke digital certificates."

Message Authentication Codes----------------------------------------------------
Asymmetric cryptography isn't the only way to authenticate. We now explore a
symmetric key authentication system.
Suppose Alice and Bob both know the secret key K. Alice sends a message m and a
signature MAC created by MAC = h(K || m) where h is some one way hash.

Certain hash functions are not secure like SHA-1, SHA-2 and md5 which are
vulnerable from the Merkle–Damgård construction. They are susceptible to
length extension attacks [never explained].
Instead we use HMAC which solves this issue.
HMAC(K,m) = H((K XOR opad) || H((K XOR ipad) || m))
where opad is the inner padding, constant
ipad is the outer padding also constant
HMAC is the most widely used MAC currently.

Should be noted that HMAC isn't the only solution. Using SHA-3 for the MAC is
also possible and is still immune to length extension attacks.

TLS/SSL------------------------------------------------------------------------
Secure Socket Layer (SSL) also known as Transport Layer Security (TLS)
sits between the application layer and a reliable transport layer.

TLS has the following main features.
Handshake protocol which establishes a shared secret key and negotiates which
cipher to use.
Cipher Change protocol escalates connection to use the cipher.
Alert protocol reports errors
Record protocol provides the security and is the main part.
With these features SSL provides; key establishment, authentication,
confidentiality and integrity.

The record protocol works as such.
First fragment the message into parts. Each part is compressed then a MAC is
added to each part. The entire segment is then encrypted and then the transport
layer header is added.

HTTPS (HTTP over SSL) uses port 443 compared to standard HTTP which uses 80.

The cipher suite we decide from is represented as such.
TLS_RSA_WITH_DES_CBC_SHA
TLS_DH_anon_WITH_RC4_128_MD5

where the RSA or DH_anon is the key establishment
DES_CBC or RC4_128 is the cipher and
SHA or MD5 is the HMAC used.

In SSL the server MUST authenticate itself during the handshake. The client and
authenticate themselves optionally.

Though the standard of SSL is sound and cannot be attacked (yet),
implementations have vulnerabilities.
Heartbleed was an implementation bug in OpenSSL.
You could also ask servers and browsers to downgrade SSL version in a
version rollback attack.

[59:00 week 7 video]

Permission systesm-------------------------------------------------------------
The idea of using rwsr-xrwx (where s is the SUID or set user id feature) is
called the access control list. An access control list has users (subjects)
and groups which have permissions to do certain operations (access operations)
on certain objects. The passwd command has to change the /etc/passwd file so how
does it do it safely? By using the set uid.

Doing this ACL for each individual user is tedious and prone with large problems
as we scale up. Instead we implement groups (or roles). Some policies allow
membership to multiple groups but only some (Linux does).

An alternative model for managing access rights is capabilities. A capability is
an object-rights pair. Think of it like tickets are licenses. If you hold the
ticket then you're allowed to write/read that object.
The system then stores all these capabilities in a table where the rows are the
users/subjects.
This method makes it easy to see the permissions of individuals and easier to
control those capabilities but is much harder to see who has access to an
object; one to many vs many to one.
This system is rarely used anywhere except niche systems.

Who determines the access privileges of the file? In UNIX and Windows the owner
determines these things. This is called Discretionary Access Control (DAC). It's
called such because it's at the discretion of the owner.
The only exception to this is restricting the root user which is not (and should
not be) possible.

One of the problems with DAC is that the power of the file is given purely to
the owner. If the owner messes up or is tricked then this new person has power
over the file. One such trick is a trojan horse (which is a form of malware).
By running the (apparently benign) program the attacker is able to execute
commands through the owner.

An alternative method is Mandatory Access Control (MAC)
which forces objects to adhere
to system-wide policies rather than the whim of the object's owner. This
alternative is often used in military and other high security contexts.

In MAC each object has a classification indicating its sensitivity.
Each user has a clearance indicating what level of sensitivity they can access.
When a user has access we say the clearance "dominates" the classification.

Of course this method fails the need-to-know principle. Thus at each
classification level we also have compartments.
Users only have access to their level of classification within their assigned
compartments.

We go a step further and develop an ordering for sensitivity level
and compartment. For example
{top secret} \geq {secret}
{top secret, nuclear} \geq {secret, nuclear}
{top secret, crypto} ?? {secret, nuclear}
Where the ?? is for a relation that isn't defined

Basic ordering properties must be met.
A \geq B and B \geq C imples A \geq C (transitivity)
A \geq A (reflexive)
A \geq B and B \geq A implies A = B (antisymmetry)
Note that not all elemnts need to be comparable.

An older model for access control is the Bell-LaPadula (BLP) model.
It follows the same clearance and classification as before. It implements two
unique rules.
Simple Security Property which prevents reading of a higher classification.
(No Read Up)

*(star)-property which prevents users of certain level to writing lower level
stuff. Subjects in the Secret classification are allowed to write Top-Secret
objects. (No Write Down)

The star-property is designed to prevent trojan horses which could create an
unclassified copy of a file.
Of course you see the problem with this method. The security levels of files
will go up as more people read and change a document. This effect is known as
a High Water Mark.

Information theory--------------------------------------------------------------
Claude Shannon (1916 - 2001)
Was one of the first people to publish a paper on information.
Shannon defined "Information is reduction of uncertainty"
We represent information in the units of bits.

I(X) is the average amount of information gained from observing the outcome of
random variable X.

Equivalently, I(X) is the minimum average number of bits needed to encode all
possible outcomes of X.

In other contexts Shannon"s definition of information is commonly called
entropy.
"My greatest concern was what to call it. I thought of calling it 'information',
but the word was overly used, so I decided to call it 'uncertainty'. When I
discussed it with John von Neumann, he had a better idea. Von Neumann told me,
'You should call it entropy, for two reasons. In the first place your
uncertainty function has been used in statistical mechanics under that name, so
it already has a name. In the second place, and more important, nobody knows
what entropy really is, so in a debate you will always have the advantage.'"

We begin with Ralph Hartely's attempt at quantifying information 20 years before
Shannon did.
We calculate the amount of information we need by taking how many bits are
required to hold all possible outcomes.
e.g.
Tossing a coin takes 1 bit
Rolling a 4 sided dice requires 2 bits.
Rolling an 8 sided dice requires 3 bits.
Rolling an N sided dice requires log_2 N bits.

Note, when all the outcomes share the same probability then we can rewrite our N
in terms of the probability instead.
p = 1/N
N = 1/p thus
I(X) = log_2 N = log_2(1/p) = - log_2(p)

Of course the next question is how we deal with different probabilities?
Enter Shannon's attempt.
We now consider information as the level of surprise. e.g. Not winning the
Gold Lotto gives less information than winning the Gold Lotto.
With this new definition we use the same - log_2(p) formula and we're now
allowed to use different p for different outcomes.
We then take the weighted average of all sizes of information to get the total
information.
Instead of I(X) which was used to denote Hartley's information we instead use
H(X) to denote Shannon's.

Understanding entropy will allow us to measure the effectiveness of some
passwords.

[Week 8 done]

IPsec----------------------------------------------------------------------
TCP/IP was designed in the late 70s and early 80s.
TCP/IP did not have any data integrity or confidentiality.
You could fake the source IP address if desired.
Replay attacks were possible since no dates or nonces.

Because of this we must decide to put security on some level.
Application level: SSH and PGP
Above transport layer: SSL/TLS
Above IP layer: IPsec

The IPsec architectures contains three key areas,
ESP (Encapsulating Security Payload)
AH (Authentication Header)
IKE (Internet Key Exchange)

There are two modes of IPsec:
Transport mode (aka host mode) only encrypts the TCP header and no anything
below it. In transport mode both client and host have knowledge of
IPsec. This is used in end-to-end scenarios.

IKE-----------------------------
An established connection is called a Security Association (SA)
We first setup *ISAKMP* (Internet Security Association and Key Management)
which uses X.509 certification for authentication and
Diffie-Hellman to exchange keys.

Once we have these parts we can generate the IPsec SA

In tunnel mode the whole packet including the original IP address
headers are encoded and packaged in another IP header. The routers
that send and receive packets are the routers much like what we did
in COMP3301 with the tunnels. This is used in end-to-intermediate.
The Maximum Segment Size is less than advertised in this scenario.

AH----------------------------------
The Authentication Header not only provides authentication but also
ensures data integrity as it contains a 96-bit hash. It also protects
against replay attacks since it has a 32-bit monotonically increasing counter.

Should be noted that it does not provide confidentiality.

The AH is placed just before the TCP header in transport mode and
just before the old IP header in tunnel mode.

There is one octet contains the type of next header
(IP:4, TCP:6, UDP:17, ESP:50, AH:51)

There is one octet also contains the length of the AH header.

There are two octets unused (reserved).

There are four octets for the SPI (Security Parameter Index)

There are four octets for the sequence number.

There is a variable number of octets for authentication data.
This takes the HMAC of the immutable fields in the IP header.

The idea of immutable fields refers to the values in the header that
cannot change. These include the SPI, the sequence number, etc.

You may notice that there is no explicit definition of mode in this header.
The mode is determined by the first parameter which was the type of the
next header.

ESP-------------------------------------
The Encapsulating Security Payload provides source authentication and
data integrity. It makes use of the same 32-bit counter as AH.

But it provides data confidentiality using symmetric keys.

The ESP header is placed in the same place as the AH header.
But now there is also an ESP trailer and ESP Authentication.
These are both placed at the end of the packet in the respective order.

The ESP trailer is there to ensure the symmetric cipher has enough
padding to work.

[See images/esppacket.png for header details]

Note that in tunnel mode the new IP address is not authenticated.

ESP is often used to implement VPNs

SA---------------------------------------
Security Associations are asymmetric (uni-directional)
Thus you need an SA for inbound traffic and an SA for outbound.
For bidirectional you will need to SAs one for the inbound of A (which
is also the outbound of B) and one for the outbound of B (vice versa).

All this information is stored in a Security Association Database (SAD)
This along with a Security Policy Database (SPD) allows the computer to
correctly handle IPsec packets.

The SPD is two steps removed from the actual processing.
Imagine we're using the SPD for
outgoing packets (though inbound is also possible),
to decide what SAD entries should be used, and the SAD
entries in turn describe the actual processing (SAD contains the SPI).

You will notice that the SPD contains a lot of information from the SAD entry
this is okay in the case that there is no suitable entry in the SAD.
In this case we use the SPD to create an SAD entry.

[See inboundprocess.png and outboundprocess.png for clearer explanation]

Intrusion Detection Systems (IDS)-------------------------------------------
An intrusion is a set of actions that attempt to compromise the
CIA of computing resources via causing DoS, backdoors, planting viruses
or exploiting viruses.

We assume that it is possible to monitor activity of programs and users.
From this we come up with 3 simple steps,
1. Monitoring and analysing host/network
2. Identifying misuse/abnormal activities
3. Assessing severity and raising alarm

A good IDS needs high detection rate with low false alarms and
minimum overhead.

We can classify IDSs as either misuse detection and anomaly detection.

We can gather data via:
Host based detection (command log and system calls),
Network based detection (packet headers and general traffic),
or both

Misuse detection
is identifying the patterns of well known attacks
to identify intrusion. From this we also record the intrusions that occur
to learn. The problem here is that we struggle to detect new attacks.

Anomaly detection
is kinda the opposite. Instead we search for deviation from normal usage
to identify intrusions. We must first establish what is normal behaviour
and then report deviations.
This has the issue of high false positive rates since a new action may be
benign.

Host-based Intrusion Detection System (HIDS) is OS dependent and is installed
inside the host (possible to attack?)

Network Intrusion Detection System (NIDS) is based on the packet capturing
of the network.

SNORT is a NIDS system and is the most widely used one in the world.
It can even analyse streams, not only single packets at a time.

SNORT first takes a packet and decodes it, then preprocesses it then
runs it through a detection engine. If it's part of the rules of logging
it is then logged and checked in the alerting system.

SNORT is a signature based IDS thus they implement two phases of detection.
Phase 1 involves pattern matching. In Phase 2 we detect more complex patterns
based on what type of packet is actually being sent, SNORT supports 36 rules.

Another way to detect is SVM-IDSs. IDS use Support Vector Machines (SVM).
This is pattern matching and categorising much like what we see in
data science and machine learning.

Cooperative IDS use collective info from others to make intrusion detection
more accurate.

Intrusion Prevention Systems (IPS)-------------------------------------
IPS is commonly an extension of intrusion detection. Since an IDS device
is passive we would like something more active.

This is more preferable since network attacks can happen fast and only need a
small amount of time to complete the attack.

Should be noted that though IDS is cheap and even open source IPS is very
EXPENSIVE.

Security Information Event Management (SIEM)--------------------------
Many large organisations receive an insane number of alerts many of which are
false alarms. We have a few ways to solve this,
Alert clustering which groups alerts together in meaningful ways.
We could only alert if we match a predefined attack scenario. (Matching
predefined attack scenarios)
We could also check if the attack could be successful in our system
and if so what would the outcome be. (Prerequisites/Consequences)

A SIEM
takes the logs and events and aggregates them. (Normalising and analysing)
For example, taking from networks, systems, applications etc.
We create a higher alarm if we find several related events happening.
This gives us a higher chance that we've detected an attack.

Honeypots----------------------------------------------
These are decoy systems designed to lure potential attackers away from
critical systems, collect information about the attacker's activity
and encourages the attacker to stay on the system long enough for
administration to respond.

Filled with fabricated information that a legitimate user of the system
wouldn't access. Once the hackers are within the network,
admin can observe behaviour.
