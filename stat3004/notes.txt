Intuition: Stochastic just means random.
Examples: Branching processes, Poisson processes, Markov chains (discrete time and continuous time), Random walks
Definition: A stochastic process (X(t), t in T)
is a collection of random variables indexed by
some indexed set T.
Intuition: Think of an array (finite or infinite) that returns a "random" number
at each t.

T is a totally ordered set. T could be the natural number or even the reals.
T is usually considered time. This implies the stochastic process X(t) has
order, a story, a known chain.

You can have a thing called a random field where T has no order.

Much like with a random variable Y we can specify the probabilistic behaviour
of a stochastic process X via its Finite-dimensional Distribution (FDD).

A FDD is specified by,
P(X(t1) <= x1, X(t2) <= x2, ... , X(tn) <= xn)
Seems familiar to a CDF in STAT2003.
Note: X could return an n-dimensional vector.

If X(t) (subset of) E (where E is some set)
then E is a statespace for X. E is where X takes all its values from.

X(t;Omega) means the stochastic process given Omega. X(t;Omega) is called a
sample path. (name should make usage obvious)

Branching Processes----------------------------------------------------
Recall the probability generating function from STAT2003. (It only works for
discrete random variables)
G(z) = Expectation z^X
G(1) = 1

It can also be represented by,
G(z) = sum from k=0 to infinity of z^k P(X=k)

G(0) = P(X=0)

Note that PGF this is also a polynomial!
Probabilities are always positive so we have a purely positive polynomial.
u <= v then G(u) <= G(v) (This is due to the fact that the PGF might be an
infinite series of terms ergo only [0,1] actually converges)

We take the derivatives for the PGF,
G'(0) = P(X=1)
G(differentiate k times) (0) / k! = P(X=k)

Observe that if two random variables share a PGF then they are exactly equal.

The lecturer derives the PGF of Poisson and Geometric distributions.
(See 23 July at 00:00)

We consider a stochastic process (S) where each "animal" has a random number
of children (X). (See W01-Branching_Processes_II.pdf)
We start the process off with S_0 = 1. X_{i,n} is the number of offspring of the i^{th}
individual of the n^{th} generation.
To simplify we let X = X_{i,n} for all i and n, it's the same probability for
everyone (also all independent).

Will the animals become extinct? Does there exist a generation m such that
S_m = 0?

Perhaps an easier question is, the expected population of generation n.

Tricks we will use:
Expectation X = Expectation(Expectation(X | Y))
E[g(x)h(y)|X] = g(x) E[h(y)|X]
If X and Y are independent E[g(x)h(y)|X] = g(x) E[h(Y)]

We base the generation n off the generation n-1.
E(S_n) = E[sum from 1 to S_{n-1} of all X_{i,n-1}] (using trick number 1)
E(S_n) = E[E[sum from 1 to S_{n-1} of all X_{i,n-1} | S_{n-1}]]
E(S_n) = E[sum from 1 to S_{n-1} of all E[X_{i,n-1} | S_{n-1}]] (since X_{i,n-1} and S_{n-1} are independent)
E(S_n) = E[sum from 1 to S_{n-1} of all E[X_{i,n-1}]] (we assumed earlier all X_{i,n} are iid)
E(S_n) = E(X) E[S_{n-1}]

(We shall call E(X) = mu)

Now also using are initial condition S_0 = 1 we get
S_1 = mu
S_2 = mu^2
S_3 = mu^3
...
S_n = mu^n

This is clearly a geometric progression.
mu < 1 then it approaches 0
mu = 1 then population remains 1
mu > 1 then population blows up

We can repeat this process to find the variance of each generation.

Var(S_n) = E(Var(S_n | S_{n-1})) + Var(E[S_n | S_{n-1}]) (This is a law called the law of total variance)

We attempt to solve the first term of this equation:
Var(S_n | S_{n-1}) = Var(sum from 1 to S_{n-1} X_{i,n-1} | S_{n-1}) (Using something similar to what was done previously)
Var(S_n | S_{n-1}) = S_{n-1} sigma^2 (We already found expectation of S_{n-1})
Now we find the expected variance
E[Var(S_n | S_{n-1})] = E[S_{n-1}] sigma^2
(sigma is variance of X)
E[Var(S_n | S_{n-1})] = mu^{n-1} sigma^2 (does not apply for n=0)

We solve the second term:
E[S_n | S_{n-1}] = mu S_{n-1}
Var(E[S_n | S_{n-1}]) = Var(mu S_{n-1})
Var(E[S_n | S_{n-1}]) = mu^2 Var(S_{n-1})

Thus our final solution is,
Var(S_n) = mu^{n-1} sigma^2 + mu^2 Var(S_{n-1})

This is now a recursive definition. We can actually expand it to give us,
Var(S_n) = sigma^2 mu^{n-1} (1 + mu + mu^2 + ... + mu^{n-1}) (not for 0)
An even better form is,
Var(S_n) = sigma^2 n when mu = 1
Var(S_n) = sigma^2 mu^{n-1} (1-mu^n)/(1-mu) for all others

Observe:
mu < 1 then Var(S_n) approaches 0 as n approaches infinity
mu >= 1 then Var(S_n) approaches infinity as n approaches infinity

Now we may ask the earlier question about probability of extinction
eta_n is probability of extinction at nth generation
eta_0 = 0 since S_0 = 1

We want to find P(S_n = 0) when n approaches infinity
P(S_n = 0) = P(S_n < 1)
= 1 - P(S_n >= 1)

We now use Markov inequality

Markov's inequality-----------------------------------------------------------
For ANY random variable X >= 0
and any a > 0
P(X >= a) <= Expectation(X)/a

I{event A} = 1 if event A occurs and 0 otherwise

Proof:
E[X] = E[X I{X<a} + X I{X >= a}]
E[X] = E[X I{X<a}] + E[X I{X >= a}]
E[X I{X<a}] is greater than zero from the initial statements
E[X] <= 0 + E[X I{X >= a}]
E[X] <= 0 + a E[I{X >= a}] [I don't know how E[X I{X >= a}] <= a E[I{X >= a}]]
E[X] <= 0 + a P(X >= a) [I don't know how E[X I{X >= a}] <= a E[I{X >= a}]]

Coming back to our previous question...
1 - P(S_n >= 1)
P(S_n >= 1) <= E(S_n)/1 = mu^n

Thus we can conclude that if mu < 1 then extinction is 100%

We currently know a few things about the probability of extinction.
eta = 1 when mu < 1
eta = 0 mu >= 1 AND variance = 0

We now attempt to find what happens when mu >= 1 and variance != 0.
eta_n = P(S_n = 0)
= E[P(S_n = 0 | S_1)] (We could've done this for any abitrary S_m)
= sum from 0 to infinity P(S_1 = k) P(S_n = 0 | S_1 = k) (definition of expectation)
= sum from 0 to infinity P(X = k) P(S_n = 0 | X = k) (Since S_0 = 1 and recall X is the number of children of a single animal)
The probability we go extinct is determined by all animals in the previous generation failing to bear children thus,
= sum from 0 to infinity P(X = k) P(S_{n-1} = 0)^k
We observe this is the PGF of eta_{n-1}!
= G(eta_{n-1})

Since we have a fixed initial state we can actually generate each eta_n.

(See 24 July at 23:00 if things are confusing or require justification)

Now we want to find eta_infinity or just eta which requires eta = G(eta).
This is a fixed point solution. In our solution we already know of G(1) = 1,
which is extinction, but are there more?

We highlight some more useful facts about the PGF. It is an upwards curving
function (at least on [0,1])

This means there are only two possible curves we can get. (See 24 July at 23:00)

Option 1 which has two fixed points. (1,1) (extinction) and somewhere else. It is caused by mu > 1.
Option 2 has the single fixed point at extinction. It is caused by mu <= 1.

By using the fixed point algorithm from COSC2500 we can find the fixed point
solutions. Also note that in Option 1 the interesting fixed point is stable
while the one at extinction is unstable. In comparison, Option 2 has extinction
as a stable fixed point.

(The lecturer then gives some examples of different X variables and solves them 24 July at 43:00)

[ZZZ Stopped at 24 July]

Random walks-------------------------------------------------------------------
The most elementary stochastic process is an infinite set of iid variables.
(This is not interesting since it's just a bunch of independent states).

Perhaps a more interesting process would be a random walk.
We define the scenario as such. Where S_i is the i^{th} state of the
random walk while X_i is some random variable (the Xs should all be iid).
S_0 = X_0 = x_0 (starting)
S_n = S_{n-1} + X_n

If we were to evaluate and expand this recursive definition we would find
That S_n is just a sum of many iid random variables. By the Central
Limit Theorem this means that S_n approximates a normal distribution.

S and X do not need to have the same state-space (Bernoulli and Binomial).

An example could be coin flips which determine
walk forward or not at all.
Coin flips are Bernouilli [spell check] and summing these coin flips gives
Binomial distribution.
It is important to remember that these random variables are dependent of
each other. e.g. S_{n+1} | S_n \sim S_n + Ber(p) and
S_{n+k} | S_n \sim S_n + Bin(k,p)

[see 29 July 30:00 for proof]

Magically we find the the Covariance of S_{n+k} and S_n is np(1-p) for
our above example.

Using this we can find our correlation to be \sqrt{\frac{n}{n+k}}

We explore a new question with random walks. Does the walker reach a desired
destination and if they do when?

Side note, if the walker is required to move every step then the walker is
required to flip odd and even number locations at each time step. (pretty neat)

Let \tau_d be the first time the random walker reaches the desired destination.
If we never reach home then \tau = \infty.
Another way to define \tau_d is the infinum of the set {n \in naturals : S_n = d}
(the set of times n that satisfy the random walker achieving a desired value)

We redefine our question concisely as P(\tau_d < \infty)

We define r_k = P(\tau_d < \infty | S_0 = k)
r is the probability that we reach our destination in finite time knowing
our starting position was k. Our question gets redefined again to become
what is r_0?

We observe a trivial case, r_d (the starting position is the desired position)
gives certain chance.

We also note that r_{d-i} = r_{d+i} there is equal chance getting i steps
away from the starting point on either side.

We perform a method called First-step analysis (aka conditioning).
This method involves considering everything that could happen in one unit
of time.
We expand r_k using conditional probability,
r_k = P(\tau_d < \infty | S_0 = k)
= P(\tau < \infty | S_0 = k, X_1 = +1) P(X_1 = +1 | S_0 = k)
+ P(\tau < \infty | S_0 = k, X_1 = -1) P(X_1 = -1 | S_0 = k)

We note that P(X_1 = +1 | S_0 = k) are independent so in reality it's just
P(X_1 = +1) which we'll assume is \frac{1}{2} for an unbiased random walk.
r_k = \frac{1}{2} (P(\tau < \infty | S_0 = k, X_1 = +1) + P(\tau < \infty | S_0 = k, X_1 = -1))

We further simplify since knowing S_0 = k and X_1 = +1 we in actuality know
S_1 = k+1.
r_k = \frac{1}{2} (P(\tau < \infty | S_1 = k+1) + P(\tau < \infty | S_1 = k-1))

Now we note that time is arbitrary and we let time 1 = 0 and time 0 = -1
r_k = \frac{1}{2} (P(\tau < \infty | S_0 = k+1) + P(\tau < \infty | S_0 = k-1))

From here we realise these are just the r_k definition again
r_k = \frac{1}{2} (r_{k+1} + r_{k-1})

We said earlier that r_{d-i} = r_{d+i} (we're letting d=0)
r_k = r_{k-1}

This works for all k and we also know that r_0 = 1 thus r_k = 1.

[To see another two examples of using single-step analysis see 31 July 00:00]
We run an example involving two \taus, bankrupt and money goal.
He goes indepth on this example and how to solve it.
Another example takes into consideration that time is important (previously
we recentered time but now we can't)

[ZZZ stopped at 31 July]
