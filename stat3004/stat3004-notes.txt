Intuition: Stochastic just means random.
Examples: Branching processes, Poisson processes, Markov chains (discrete time and continuous time), Random walks
Definition: A stochastic process (X(t), t in T)
is a collection of random variables indexed by
some indexed set T.
Intuition: Think of an array (finite or infinite) that returns a "random" number
at each t.

T is a totally ordered set. T could be the natural number or even the reals.
T is usually considered time. This implies the stochastic process X(t) has
order, a story, a known chain.

You can have a thing called a random field where T has no order.

Much like with a random variable Y we can specify the probabilistic behaviour
of a stochastic process X via its Finite-dimensional Distribution (FDD).

A FDD is specified by,
P(X(t1) <= x1, X(t2) <= x2, ... , X(tn) <= xn)
Seems familiar to a CDF in STAT2003.
Note: X could return an n-dimensional vector.

If X(t) (subset of) E (where E is some set)
then E is a statespace for X. E is where X takes all its values from.

X(t;Omega) means the stochastic process given Omega. X(t;Omega) is called a
sample path. (name should make usage obvious)

Branching Processes----------------------------------------------------
Recall the probability generating function from STAT2003. (It only works for
discrete random variables)
G(z) = Expectation z^X
G(1) = 1

It can also be represented by,
G(z) = sum from k=0 to infinity of z^k P(X=k)

G(0) = P(X=0)

Note that PGF this is also a polynomial!
Probabilities are always positive so we have a purely positive polynomial.
u <= v then G(u) <= G(v) (This is due to the fact that the PGF might be an
infinite series of terms ergo only [0,1] actually converges)

We take the derivatives for the PGF,
G'(0) = P(X=1)
G(differentiate k times) (0) / k! = P(X=k)

Observe that if two random variables share a PGF then they are exactly equal.

The lecturer derives the PGF of Poisson and Geometric distributions.
(See 23 July at 00:00)

We consider a stochastic process (S) where each "animal" has a random number
of children (X). (See W01-Branching_Processes_II.pdf)
We start the process off with S_0 = 1. X_{i,n} is the number of offspring of the i^{th}
individual of the n^{th} generation.
To simplify we let X = X_{i,n} for all i and n, it's the same probability for
everyone (also all independent).

Will the animals become extinct? Does there exist a generation m such that
S_m = 0?

Perhaps an easier question is, the expected population of generation n.

Tricks we will use:
Expectation X = Expectation(Expectation(X | Y))
E[g(x)h(y)|X] = g(x) E[h(y)|X]
If X and Y are independent E[g(x)h(y)|X] = g(x) E[h(Y)]

We base the generation n off the generation n-1.
E(S_n) = E[sum from 1 to S_{n-1} of all X_{i,n-1}] (using trick number 1)
E(S_n) = E[E[sum from 1 to S_{n-1} of all X_{i,n-1} | S_{n-1}]]
E(S_n) = E[sum from 1 to S_{n-1} of all E[X_{i,n-1} | S_{n-1}]] (since X_{i,n-1} and S_{n-1} are independent)
E(S_n) = E[sum from 1 to S_{n-1} of all E[X_{i,n-1}]] (we assumed earlier all X_{i,n} are iid)
E(S_n) = E(X) E[S_{n-1}]

(We shall call E(X) = mu)

Now also using are initial condition S_0 = 1 we get
S_1 = mu
S_2 = mu^2
S_3 = mu^3
...
S_n = mu^n

This is clearly a geometric progression.
mu < 1 then it approaches 0
mu = 1 then population remains 1
mu > 1 then population blows up

We can repeat this process to find the variance of each generation.

Var(S_n) = E(Var(S_n | S_{n-1})) + Var(E[S_n | S_{n-1}]) (This is a law called the law of total variance)

We attempt to solve the first term of this equation:
Var(S_n | S_{n-1}) = Var(sum from 1 to S_{n-1} X_{i,n-1} | S_{n-1}) (Using something similar to what was done previously)
Var(S_n | S_{n-1}) = S_{n-1} sigma^2 (We already found expectation of S_{n-1})
Now we find the expected variance
E[Var(S_n | S_{n-1})] = E[S_{n-1}] sigma^2
E[Var(S_n | S_{n-1})] = mu^{n-1} sigma^2 (does not apply for n=0)

We solve the second term:
E[S_n | S_{n-1}] = mu S_{n-1}
Var(E[S_n | S_{n-1}]) = Var(mu S_{n-1})
Var(E[S_n | S_{n-1}]) = mu^2 Var(S_{n-1})

Thus our final solution is,
Var(S_n) = mu^{n-1} sigma^2 + mu^2 Var(S_{n-1})

This is now a recursive definition. We can actually expand it to give us,
Var(S_n) = sigma^2 mu^{n-1} (1 + mu + mu^2 + ... + mu^{n-1}) (not for 0)
An even better form is,
Var(S_n) = sigma^2 n when mu = 1
Var(S_n) = sigma^2 mu^{n-1} (1-mu^n)/(1-mu) for all others

Observe:
mu < 1 then Var(S_n) approaches 0 as n approaches infinity
mu >= 1 then Var(S_n) approaches infinity as n approaches infinity

Now we may ask the earlier question about probability of extinction
eta_n is probability of extinction at nth generation
eta_0 = 0 since S_0 = 1

We want to find P(S_n = 0) when n approaches infinity
P(S_n = 0) = P(S_n < 1)
= 1 - P(S_n >= 1)

We now use Markov inequality

Markov's inequality-----------------------------------------------------------
For ANY random variable X >= 0
and any a > 0
P(X >= a) <= Expectation(X)/a

I{event A} = 1 if event A occurs and 0 otherwise

Proof:
E[X] = E[X I{X<a} + X I{X >= a}]
E[X] = E[X I{X<a}] + E[X I{X >= a}]
E[X I{X<a}] is greater than zero from the initial statements
E[X] <= 0 + E[X I{X >= a}]
E[X] <= 0 + a E[I{X >= a}] [I don't know how E[X I{X >= a}] <= a E[I{X >= a}]]
E[X] <= 0 + a P(X >= a) [I don't know how E[X I{X >= a}] <= a E[I{X >= a}]]

Coming back to our previous question...
1 - P(S_n >= 1)
P(S_n >= 1) <= E(S_n)/1 = mu^n

Thus we can conclude that if mu < 1 then extinction is 100%

We currently know a few things about the probability of extinction.
eta = 1 when mu < 1
eta = 0 mu >= 1 AND variance = 0

We now attempt to find what happens when mu >= 1 and variance != 0.
eta_n = P(S_n = 0)
= E[P(S_n = 0 | S_1)] (We could've done this for any abitrary S_m)
= sum from 0 to infinity P(S_1 = k) P(S_n = 0 | S_1 = k) (definition of expectation)
= sum from 0 to infinity P(X = k) P(S_n = 0 | X = k) (Since S_0 = 1 and recall X is the number of children of a single animal)
The probability we go extinct is determined by all animals in the previous generation failing to bear children thus,
= sum from 0 to infinity P(X = k) P(S_{n-1} = 0)^k
We observe this is the PGF of eta_{n-1}!
= G(eta_{n-1})

Since we have a fixed initial state we can actually generate each eta_n.

(See 24 July at 23:00 if things are confusing or require justification)

Now we want to find eta_infinity or just eta which requires eta = G(eta).
This is a fixed point solution. In our solution we already know of G(1) = 1,
which is extinction, but are there more?

We highlight some more useful facts about the PGF. It is an upwards curving
function (at least on [0,1])

This means there are only two possible curves we can get. (See 24 July at 23:00)

Option 1 which has two fixed points. (1,1) (extinction) and somewhere else. It is caused by mu > 1.
Option 2 has the single fixed point at extinction. It is caused by mu <= 1.

By using the fixed point algorithm from COSC2500 we can find the fixed point
solutions. Also note that in Option 1 the interesting fixed point is stable
while the one at extinction is unstable. In comparison, Option 2 has extinction
as a stable fixed point.

(The lecturer then gives some examples of different X variables and solves them 24 July at 43:00)

[ZZZ Stopped at 24 July]
